{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Classification\n",
    "This notebook trains classifiers to detect cancer in MRI scans, using automated labels from the LLM pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import misvm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, balanced_accuracy_score, roc_curve\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ivd_arrays_path = '/work/robinpark/NCIMI_clean/ncimi_ivd_arrays/april2024_splits'\n",
    "\n",
    "# SEED\n",
    "seed=0\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the dictionary\n",
    "with open(f'{ivd_arrays_path}/ncimi_samples_dict.pkl', 'rb') as handle:\n",
    "    samples = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = samples['train_samples']\n",
    "val_samples = samples['val_samples']\n",
    "test_samples = samples['test_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise splits\n",
    "def sum_samples(samples):\n",
    "    df = pd.DataFrame.from_dict(samples, orient='index', columns=['results']).reset_index()\n",
    "\n",
    "    # Split index into columns\n",
    "    df[['pat_id','stu_id','ser_id','level1','level2']] = df['index'].str.split('_',expand=True)\n",
    "\n",
    "    # Sum rows by pat_id, date, level, and unique results \n",
    "    df = df.groupby(['pat_id','stu_id','ser_id','level1','level2', 'results']).size().reset_index(name='counts')\n",
    "\n",
    "    df['pat_stu_id'] = df['pat_id'] + '_' + df['stu_id']\n",
    "\n",
    "    print('unique pat:', len(df[['pat_id']].drop_duplicates()))\n",
    "    print('unique studies:', len(df[['pat_stu_id']].drop_duplicates()))\n",
    "\n",
    "    display(df.groupby(['results'])[['counts']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique pat: 1235\n",
      "unique studies: 1265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         counts\n",
       "results        \n",
       "0          5337\n",
       "1          8924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_samples(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique pat: 312\n",
      "unique studies: 318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         counts\n",
       "results        \n",
       "0          1281\n",
       "1          2237"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_samples(val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique pat: 450\n",
      "unique studies: 451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         counts\n",
       "results        \n",
       "0          1798\n",
       "1          3120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_samples(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 Encodings + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{ivd_arrays_path}/ncimi_resnet_encodings.pkl', 'rb') as handle:\n",
    "    ncimi_resnet_encodings = pickle.load(handle)\n",
    "\n",
    "train_features_cpu = ncimi_resnet_encodings['train_features_cpu']\n",
    "label_train_array = ncimi_resnet_encodings['label_train_array']\n",
    "\n",
    "val_features_cpu = ncimi_resnet_encodings['val_features_cpu']\n",
    "label_val_array = ncimi_resnet_encodings['label_val_array']\n",
    "\n",
    "test_features_cpu = ncimi_resnet_encodings['test_features_cpu']\n",
    "label_test_array = ncimi_resnet_encodings['label_test_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled arrays\n",
    "with open(f'{ivd_arrays_path}/ncimi_arrays_dict.pkl', 'rb') as handle:\n",
    "    ncimi_array_dict = pickle.load(handle)\n",
    "\n",
    "label_test_report = ncimi_array_dict['label_test_report']\n",
    "label_test_scores = ncimi_array_dict['label_test_scores']\n",
    "label_test_con = ncimi_array_dict['label_test_con']\n",
    "compare_test_array = ncimi_array_dict['compare_test_array']\n",
    "\n",
    "test_pat_id_date = ncimi_array_dict['test_pat_id_date']\n",
    "val_pat_id_date = ncimi_array_dict['val_pat_id_date']\n",
    "train_pat_id_date = ncimi_array_dict['train_pat_id_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise\n",
    "scaler = StandardScaler()\n",
    "train_features_cpu = scaler.fit_transform(train_features_cpu)\n",
    "val_features_cpu = scaler.transform(val_features_cpu)\n",
    "test_features_cpu = scaler.transform(test_features_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cpu = [torch.Tensor(i) for i in train_features_cpu]\n",
    "val_features_cpu = [torch.Tensor(i) for i in val_features_cpu]\n",
    "test_features_cpu = [torch.Tensor(i) for i in test_features_cpu]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Using Max Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_bag(features, labels, patient_slices):\n",
    "    # Combine features, labels, and patient slices into a DataFrame\n",
    "    df = pd.DataFrame({'Features': features, 'Labels': labels, 'Patient_Slices': patient_slices})\n",
    "    \n",
    "    # Group by patient\n",
    "    grouped = df.groupby('Patient_Slices')\n",
    "    \n",
    "    mil_bags = []\n",
    "    mil_label = []\n",
    "    \n",
    "    for patient_slice, group in grouped:\n",
    "        # Combine slices into a bag\n",
    "        bag_features = group['Features'].tolist()\n",
    "        \n",
    "        bag_label = group['Labels'].max()\n",
    "        # if bag_label == 0:\n",
    "        #     bag_label = -1\n",
    "        \n",
    "        # Add bag to MIL bags\n",
    "        mil_bags.append(bag_features)\n",
    "        mil_label.append(bag_label)\n",
    "\n",
    "    max_bags = []\n",
    "    for bag in mil_bags:\n",
    "        max_bag, _ = torch.max(torch.stack(bag), dim=0)\n",
    "        max_bags.append(max_bag)\n",
    "    \n",
    "    return max_bags, mil_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_bags, train_labels = get_max_bag(train_features_cpu, label_train_array, train_pat_id_date)\n",
    "test_max_bags, test_labels = get_max_bag(test_features_cpu, label_test_array, test_pat_id_date)\n",
    "val_max_bags, val_labels = get_max_bag(val_features_cpu, label_val_array, val_pat_id_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 172]\n",
      " [  1 279]]\n"
     ]
    }
   ],
   "source": [
    "# Count the values in train_lables\n",
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative bags\n",
    "pos_train_bags = [bag for bag, label in zip(train_max_bags, train_labels) if label == 1]\n",
    "neg_train_bags = [bag for bag, label in zip(train_max_bags, train_labels) if label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double the negative examples to balance\n",
    "neg_train_bags_rs = neg_train_bags + neg_train_bags[:round(len(neg_train_bags)*.65)]\n",
    "\n",
    "train_max_bags_rs = pos_train_bags + neg_train_bags_rs\n",
    "train_labels_rs = [1] * len(pos_train_bags) + [0] * len(neg_train_bags_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_train_bags_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 810]\n",
      " [  1 774]]\n"
     ]
    }
   ],
   "source": [
    "# Count the values in train_lables\n",
    "unique, counts = np.unique(train_labels_rs, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;, probability=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, kernel='linear', probability=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize SVM classifier\n",
    "svm_classifier = svm.SVC(kernel='linear', C=100, probability=True)\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(train_max_bags_rs, train_labels_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.648\n",
      "Val AUC: 0.708\n",
      "Validation F1: 0.702\n",
      "Validation Balanced Accuracy: 0.640\n",
      "EER: 0.369\n",
      "EER Threshold: 0.582\n",
      "\n",
      "Test Accuracy: 0.659\n",
      "Test AUC: 0.711\n",
      "Test F1: 0.705\n",
      "Test Balanced Accuracy: 0.658\n",
      "EER: 0.343\n",
      "EER Threshold: 0.592\n"
     ]
    }
   ],
   "source": [
    "# Predict the validation set\n",
    "val_pred = svm_classifier.predict(val_max_bags)\n",
    "val_prob = svm_classifier.predict_proba(val_max_bags)[:, 1]\n",
    "\n",
    "# Evaluate using AUROC, F1 and balanced accuracy\n",
    "val_auc = roc_auc_score(val_labels, val_prob)\n",
    "val_f1 = f1_score(val_labels, val_pred)\n",
    "val_bal_acc = balanced_accuracy_score(val_labels, val_pred)\n",
    "val_acc = np.mean(val_pred == val_labels)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(val_labels, val_prob)\n",
    "\n",
    "# Find the point where FPR equals FRR\n",
    "val_eer_threshold = thresholds[np.nanargmin(np.absolute((1 - tpr) - fpr))]\n",
    "val_eer = fpr[np.nanargmin(np.absolute((1 - tpr) - fpr))]  # Equal to FRR\n",
    "\n",
    "print(f'Val Accuracy: {val_acc:.3f}')\n",
    "print(f'Val AUC: {val_auc:.3f}')\n",
    "print(f'Validation F1: {val_f1:.3f}')\n",
    "print(f'Validation Balanced Accuracy: {val_bal_acc:.3f}')\n",
    "print(f'EER: {val_eer:.3f}')\n",
    "print(f'EER Threshold: {val_eer_threshold:.3f}\\n')\n",
    "\n",
    "# Predict test set\n",
    "test_prob = svm_classifier.predict_proba(test_max_bags)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, test_prob)\n",
    "\n",
    "# Find the point where FPR equals FRR\n",
    "test_eer_threshold = thresholds[np.nanargmin(np.absolute((1 - tpr) - fpr))]\n",
    "test_eer = fpr[np.nanargmin(np.absolute((1 - tpr) - fpr))]  # Equal to FRR\n",
    "\n",
    "test_pred = test_prob > val_eer_threshold\n",
    "\n",
    "# Evaluate using accuracy, F1 and balanced accuracy\n",
    "test_auc = roc_auc_score(test_labels, test_prob)\n",
    "test_f1 = f1_score(test_labels, test_pred)\n",
    "test_bal_acc = balanced_accuracy_score(test_labels, test_pred)\n",
    "test_acc = np.mean(test_pred == test_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_acc:.3f}')\n",
    "print(f'Test AUC: {test_auc:.3f}')\n",
    "print(f'Test F1: {test_f1:.3f}')\n",
    "print(f'Test Balanced Accuracy: {test_bal_acc:.3f}')\n",
    "print(f'EER: {test_eer:.3f}')\n",
    "print(f'EER Threshold: {test_eer_threshold:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIL-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mil_bags(features, labels, patient_slices):\n",
    "    # Combine features, labels, and patient slices into a DataFrame\n",
    "    df = pd.DataFrame({'Features': features, 'Labels': labels, 'Patient_Slices': patient_slices})\n",
    "    \n",
    "    # Group by patient\n",
    "    grouped = df.groupby('Patient_Slices')\n",
    "    \n",
    "    mil_bags = []\n",
    "    mil_label = []\n",
    "    \n",
    "    for patient_slice, group in grouped:\n",
    "        # Combine slices into a bag\n",
    "        bag_features = group['Features'].tolist()\n",
    "        \n",
    "        bag_label = group['Labels'].max()\n",
    "        if bag_label == 0:\n",
    "            bag_label = -1\n",
    "        \n",
    "        # Add bag to MIL bags\n",
    "        mil_bags.append(bag_features)\n",
    "        mil_label.append(bag_label)\n",
    "    \n",
    "    return mil_bags, mil_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bags, train_labels = create_mil_bags(train_features_cpu, label_train_array, train_pat_id_date)\n",
    "test_bags, test_labels = create_mil_bags(test_features_cpu, label_test_array, test_pat_id_date)\n",
    "val_bags, val_labels = create_mil_bags(val_features_cpu, label_val_array, val_pat_id_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mil(model):\n",
    "\n",
    "    mil_val_scores = model.predict(val_bags)\n",
    "    mil_val_pred = np.sign(mil_val_scores)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(val_labels, mil_val_scores)\n",
    "\n",
    "    # Find the point where FPR equals FRR\n",
    "    val_eer_threshold = thresholds[np.nanargmin(np.absolute((1 - tpr) - fpr))]\n",
    "    val_eer = fpr[np.nanargmin(np.absolute((1 - tpr) - fpr))]  # Equal to FRR\n",
    "\n",
    "    print('Validation Balanced Accuracy:', balanced_accuracy_score(val_labels, mil_val_pred))\n",
    "    print('Validation F1 Score:', f1_score(val_labels, mil_val_pred))\n",
    "    print('Validation AUC:', roc_auc_score(val_labels, mil_val_scores))\n",
    "    print('Validation EER:', val_eer)\n",
    "    print('Validation EER Threshold:', val_eer_threshold)\n",
    "\n",
    "    mil_test_scores = model.predict(test_bags)\n",
    "    mil_test_pred = np.where(mil_test_scores > val_eer_threshold, 1, -1)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, mil_test_scores)\n",
    "\n",
    "    # Find the point where FPR equals FRR\n",
    "    test_eer_threshold = thresholds[np.nanargmin(np.absolute((1 - tpr) - fpr))]\n",
    "    test_eer = fpr[np.nanargmin(np.absolute((1 - tpr) - fpr))]  # Equal to FRR\n",
    "\n",
    "    print('\\nTest Balanced Accuracy:', balanced_accuracy_score(test_labels, mil_test_pred))\n",
    "    print('Test F1 Score:', f1_score(test_labels, mil_test_pred))\n",
    "    print('Test AUC:', roc_auc_score(test_labels, mil_test_scores))\n",
    "    print('Test EER:', test_eer)\n",
    "    print('Test EER Threshold:', test_eer_threshold)\n",
    "\n",
    "    return mil_test_pred, mil_test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative bags\n",
    "pos_train_bags = [bag for bag, label in zip(train_bags, train_labels) if label == 1]\n",
    "neg_train_bags = [bag for bag, label in zip(train_bags, train_labels) if label == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double the negative examples to balance\n",
    "neg_train_bags_rs = neg_train_bags + neg_train_bags[:round(len(neg_train_bags)*.65)]\n",
    "\n",
    "train_bags_rs = pos_train_bags + neg_train_bags_rs\n",
    "train_labels_rs = [1] * len(pos_train_bags) + [-1] * len(neg_train_bags_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1 810]\n",
      " [  1 774]]\n"
     ]
    }
   ],
   "source": [
    "# Count the values in train_lables\n",
    "unique, counts = np.unique(train_labels_rs, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSK-SVM\n",
    "Maps entire bags to features, using distance between two bags to generate the kernel (Gärtner et al, 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup QP...\n",
      "Solving QP...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.9795e+02 -3.5238e+01  1e+04  1e+02  1e-12\n",
      " 1: -3.2813e+01 -2.7412e+01  7e+02  6e+00  1e-12\n",
      " 2: -7.3862e+00 -2.2677e+01  7e+01  5e-01  1e-13\n",
      " 3: -4.9144e+00 -1.5330e+01  1e+01  6e-02  2e-14\n",
      " 4: -5.0589e+00 -7.0856e+00  2e+00  8e-03  9e-15\n",
      " 5: -5.4928e+00 -6.0514e+00  6e-01  2e-03  1e-14\n",
      " 6: -5.6294e+00 -5.8258e+00  2e-01  3e-04  9e-15\n",
      " 7: -5.6904e+00 -5.7297e+00  4e-02  5e-05  1e-14\n",
      " 8: -5.7045e+00 -5.7088e+00  4e-03  2e-06  1e-14\n",
      " 9: -5.7062e+00 -5.7066e+00  4e-04  2e-07  1e-14\n",
      "10: -5.7064e+00 -5.7064e+00  1e-05  6e-09  1e-14\n",
      "11: -5.7064e+00 -5.7064e+00  2e-06  9e-10  1e-14\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "nsk_svm = misvm.NSK(kernel='linear_av', C=10)\n",
    "nsk_svm.fit(train_bags_rs, train_labels_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Balanced Accuracy: 0.757694881231181\n",
      "Validation F1 Score: 0.7891891891891892\n",
      "Validation AUC: 0.8404566744730678\n",
      "Validation EER: 0.2459016393442623\n",
      "Validation EER Threshold: -0.009485154626617337\n",
      "\n",
      "Test Balanced Accuracy: 0.763367925314662\n",
      "Test F1 Score: 0.7729083665338645\n",
      "Test AUC: 0.8513378344586147\n",
      "Test EER: 0.21511627906976744\n",
      "Test EER Threshold: -0.21384291030091582\n"
     ]
    }
   ],
   "source": [
    "mil_test_pred, mil_test_scores = eval_mil(nsk_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Resnet18 Encodings + NSK-SVM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled arrays\n",
    "with open(f'{ivd_arrays_path}/ncimi_arrays_dict.pkl', 'rb') as handle:\n",
    "    ncimi_array_dict = pickle.load(handle)\n",
    "\n",
    "ivd_train_array = ncimi_array_dict['ivd_train_array']\n",
    "label_train_array = ncimi_array_dict['label_train_array']\n",
    "\n",
    "ivd_val_array = ncimi_array_dict['ivd_val_array']\n",
    "label_val_array = ncimi_array_dict['label_val_array']\n",
    "\n",
    "ivd_test_array = ncimi_array_dict['ivd_test_array']\n",
    "label_test_array = ncimi_array_dict['label_test_array']\n",
    "label_test_report = ncimi_array_dict['label_test_report']\n",
    "label_test_scores = ncimi_array_dict['label_test_scores']\n",
    "label_test_con = ncimi_array_dict['label_test_con']\n",
    "compare_test_array = ncimi_array_dict['compare_test_array']\n",
    "ivd_test_array_names = ncimi_array_dict['ivd_test_array_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mil_level_report(\n",
    "    label_test_report, label_test_con, label_test_scores, \n",
    "    compare_test_array, ivd_test_array, ivd_test_array_names, \n",
    "    patient_slices):\n",
    "    # Combine features, labels, and patient slices into a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        {'Reports': label_test_report, \n",
    "        'Conclusions': label_test_con, \n",
    "        'Label Scores': label_test_scores,\n",
    "        'Predicted Label': compare_test_array,\n",
    "        'IVD Test Array': ivd_test_array,\n",
    "        'IVD Names': ivd_test_array_names,\n",
    "        'Patient Slices': patient_slices})\n",
    "\n",
    "    # Group by patient\n",
    "    grouped = df.groupby('Patient Slices')\n",
    "    \n",
    "    bag_report = []\n",
    "    bag_con = []\n",
    "    bag_score = []\n",
    "    bag_pred_label = []\n",
    "    bag_ivd_test_array = []\n",
    "    bag_names = []\n",
    "    \n",
    "    for patient_slice, group in grouped:\n",
    "        # Combine slices into a bag\n",
    "        \n",
    "        bag_report.append(group['Reports'].iloc[0])\n",
    "        bag_con.append(group['Conclusions'].iloc[0])\n",
    "        bag_score.append(group['Label Scores'].iloc[0])\n",
    "        bag_pred_label.append(group['Predicted Label'].iloc[0])\n",
    "        bag_ivd_test_array.append(group['IVD Test Array'].tolist())\n",
    "        bag_names.append(group['IVD Names'].tolist())\n",
    "    \n",
    "    return bag_report, bag_con, bag_score, bag_pred_label, bag_ivd_test_array, bag_names\n",
    "\n",
    "(df_lab_test_report, \n",
    " df_lab_test_con, \n",
    " df_lab_test_scores, \n",
    " df_lab_pred_labels, \n",
    " bag_ivd_test_array, \n",
    " bag_of_names) = mil_level_report(label_test_report, \n",
    "                                  label_test_con, \n",
    "                                  label_test_scores, \n",
    "                                  compare_test_array, \n",
    "                                  ivd_test_array, \n",
    "                                  ivd_test_array_names, \n",
    "                                  test_pat_id_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualise outputs at each step \n",
    "# counter = 3\n",
    "# zipped_results = list(zip(df_lab_test_report, df_lab_test_con, df_lab_test_scores, df_lab_pred_labels, test_labels, mil_test_pred, mil_test_scores, bag_ivd_test_array, bag_of_names))\n",
    "\n",
    "# for report, pred_con, pred_report_score, pred_report_label, true_report_label, pred_scan_label, pred_scan_score, ivd, ivd_name in zipped_results:\n",
    "#     counter += 1\n",
    "#     if counter <7:\n",
    "#         if pred_report_label == 1 and true_report_label == 1 and pred_scan_label == 1:\n",
    "#             print(f'Report: {report}')\n",
    "#             print(f'Conclusion: {pred_con}')\n",
    "#             print(f'Predicted Report Score: {pred_report_score}')\n",
    "#             print(f'Predicted Report Label: {pred_report_label}')\n",
    "#             print(f'True Report Label: {true_report_label}')\n",
    "#             print(f'Predicted Scan Label: {pred_scan_label}')\n",
    "#             print(f'Predicted Scan Score: {pred_scan_score}')\n",
    "#             # Plot ivd\n",
    "#             for i in range(len(ivd)):\n",
    "#                 print(f'IVD: {ivd_name[i]}')\n",
    "#                 plt.imshow(ivd[i][3,:,:], cmap='gray')\n",
    "#                 plt.show()\n",
    "#             print('\\n')\n",
    "#     elif counter == 7:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
